import dlt
from dlt.sources.helpers.rest_client import RESTClient
from datetime import datetime, timedelta
import time
import logging

# Configurar logging do DLT
logger = logging.getLogger(__name__)

API_KEY = "0dc3b5990e776e55b24bd7518b245eca"
HISTORY_API_URL = "https://history.openweathermap.org/data/2.5/history/city"

CITIES = [
    # Regi√£o Sul
    {"name": "Porto Alegre", "lat": -30.0346, "lon": -51.2177},
    {"name": "Curitiba", "lat": -25.4289, "lon": -49.2671},
    {"name": "Florian√≥polis", "lat": -27.5969, "lon": -48.5495},
    {"name": "Pelotas", "lat": -31.7719, "lon": -52.3428},
    {"name": "Caxias do Sul", "lat": -29.1686, "lon": -51.1794}
]

def fetch_historical_weather_data():
    client = RESTClient(base_url=HISTORY_API_URL)
    
    total_cities = len(CITIES)
    total_days = 3
    
    logger.info("üöÄ Iniciando ingest√£o de dados clim√°ticos hist√≥ricos")
    logger.info(f"üìä Total de cidades: {total_cities}")
    logger.info(f"üìÖ Per√≠odo: {total_days} dias (dados di√°rios)")
    logger.info(f"üîó API: OpenWeatherMap History")
    logger.info("-" * 60)
    
    for city_index, city in enumerate(CITIES, 1):
        try:
            logger.info(f"üèôÔ∏è  [{city_index}/{total_cities}] Processando {city['name']}...")
            
            city_data_count = 0
            
            # Para dados di√°rios, voc√™ pode buscar per√≠odos maiores
            for day_offset in range(total_days):
                try:
                    target_date = datetime.now() - timedelta(days=day_offset)
                    
                    # Para dados di√°rios, usa o dia inteiro
                    start_timestamp = int(target_date.replace(hour=0, minute=0, second=0, microsecond=0).timestamp())
                    end_timestamp = int(target_date.replace(hour=23, minute=59, second=59, microsecond=0).timestamp())
                    
                    params = {
                        "lat": city["lat"],
                        "lon": city["lon"],
                        "type": "daily",  # Mudou de "hour" para "daily"
                        "start": start_timestamp,
                        "end": end_timestamp,
                        "appid": API_KEY
                    }
                    
                    # Log a cada 30 dias para n√£o poluir muito
                    if day_offset % 30 == 0:
                        logger.info(f"   üìÖ Buscando dados de {target_date.strftime('%Y-%m-%d')} (dia {day_offset + 1}/{total_days})")
                    
                    data = client.get("", params=params).json()
                    
                    if data.get("cod") == "200" and "list" in data:
                        for daily_data in data["list"]:
                            city_data_count += 1
                            yield {
                                "city_name": city["name"],
                                "city_id": data.get("city_id"),
                                "dt": daily_data["dt"],
                                "dt_iso": datetime.fromtimestamp(daily_data["dt"]).strftime("%Y-%m-%d %H:%M:%S"),
                                "date": datetime.fromtimestamp(daily_data["dt"]).strftime("%Y-%m-%d"),
                                "main": daily_data["main"],
                                "wind": daily_data["wind"],
                                "clouds": daily_data["clouds"],
                                "weather": daily_data["weather"],
                                "rain": daily_data.get("rain", {}),
                                "snow": daily_data.get("snow", {}),
                                "calctime": data.get("calctime"),
                                "cnt": data.get("cnt")
                            }
                    else:
                        error_msg = data.get('message', 'Erro desconhecido')
                        logger.warning(f"   ‚ö†Ô∏è  Erro na resposta para {city['name']} - {target_date.strftime('%Y-%m-%d')}: {error_msg}")
                        
                        # Se for erro de per√≠odo fora do range, para de buscar essa cidade
                        if "out of allowed range" in error_msg:
                            logger.warning(f"   üõë Parando busca para {city['name']} - dados fora do per√≠odo dispon√≠vel")
                            break
                    
                    time.sleep(0.01)  # Rate limiting
                    
                except Exception as day_error:
                    logger.error(f"   ‚ùå Erro ao processar dia {day_offset + 1} para {city['name']}: {str(day_error)}")
                    continue  # Continua para o pr√≥ximo dia
            
            logger.info(f"   ‚úÖ {city['name']} conclu√≠do - {city_data_count} registros coletados")
            
        except Exception as city_error:
            logger.error(f"‚ùå Erro cr√≠tico ao processar cidade {city['name']}: {str(city_error)}")
            continue  # Continua para a pr√≥xima cidade
    
    logger.info("-" * 60)
    logger.info("üéâ Processamento conclu√≠do!")

# Configura√ß√£o do pipeline
pipeline = dlt.pipeline(
    pipeline_name="dados_clima_historico",
    destination="postgres",
    dataset_name="dados_climaticos"
)

@dlt.resource(
    name="dados_clima_historico_daily", 
    write_disposition="merge", 
    primary_key=["city_name", "date"]
)
def weather_resource():
    yield from fetch_historical_weather_data()

if __name__ == "__main__":
    logger.info("üöÄ Iniciando pipeline DLT...")
    load_info = pipeline.run(weather_resource())
    logger.info("‚úÖ Pipeline conclu√≠do!")
    logger.info(f"üìä Informa√ß√µes do carregamento: {load_info}")